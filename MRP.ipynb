{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:10.581945Z",
     "start_time": "2018-03-04T22:01:09.492888Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 227, in <module>\n",
      "    use(config.device)\n",
      "  File \"C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 214, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\theano\\gpuarray\\__init__.py\", line 67, in init_dev\n",
      "    raise RuntimeError(\"The new gpu-backend need a c++ compiler.\")\n",
      "RuntimeError: The new gpu-backend need a c++ compiler.\n",
      "C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from misc import *\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import logit\n",
    "from theano import shared\n",
    "\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.722053Z",
     "start_time": "2018-03-04T22:01:10.582946Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Alabama', 122],\n",
       "       ['Alaska', 3],\n",
       "       ['Arizona', 110],\n",
       "       ['Arkansas', 37],\n",
       "       ['California', 536],\n",
       "       ['Colorado', 52],\n",
       "       ['Connecticut', 44],\n",
       "       ['Delaware', 9],\n",
       "       ['District of Columbia', 33],\n",
       "       ['Florida', 380],\n",
       "       ['Georgia', 196],\n",
       "       ['Hawaii', 10],\n",
       "       ['Idaho', 22],\n",
       "       ['Illinois', 286],\n",
       "       ['Indiana', 105],\n",
       "       ['Iowa', 59],\n",
       "       ['Kansas', 36],\n",
       "       ['Kentucky', 154],\n",
       "       ['Louisiana', 72],\n",
       "       ['Maine', 23],\n",
       "       ['Maryland', 112],\n",
       "       ['Massachusetts', 68],\n",
       "       ['Michigan', 279],\n",
       "       ['Minnesota', 70],\n",
       "       ['Mississippi', 47],\n",
       "       ['Missouri', 111],\n",
       "       ['Montana', 9],\n",
       "       ['Nebraska', 39],\n",
       "       ['Nevada', 36],\n",
       "       ['New Hampshire', 14],\n",
       "       ['New Jersey', 96],\n",
       "       ['New Mexico', 13],\n",
       "       ['New York', 305],\n",
       "       ['North Carolina', 220],\n",
       "       ['North Dakota', 4],\n",
       "       ['Ohio', 331],\n",
       "       ['Oklahoma', 77],\n",
       "       ['Oregon', 57],\n",
       "       ['Pennsylvania', 273],\n",
       "       ['Rhode Island', 20],\n",
       "       ['South Carolina', 64],\n",
       "       ['South Dakota', 11],\n",
       "       ['Tennessee', 137],\n",
       "       ['Texas', 487],\n",
       "       ['Unknown', 236],\n",
       "       ['Utah', 35],\n",
       "       ['Vermont', 10],\n",
       "       ['Virginia', 153],\n",
       "       ['Washington', 97],\n",
       "       ['West Virginia', 71],\n",
       "       ['Wisconsin', 92],\n",
       "       ['Wyoming', 8]], dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the survey data\n",
    "\n",
    "index1 = preprocess(pd.read_excel('data/RawData/IN10001.xls'))\n",
    "index4 = preprocess(pd.read_excel('data/RawData/IN10004.xls'))\n",
    "index5 = preprocess(pd.read_excel('data/RawData/IN10005.xls'))\n",
    "index6 = preprocess(pd.read_excel('data/RawData/IN10006.xls'))\n",
    "index7 = preprocess(pd.read_excel('data/RawData/IN10007.xls'))\n",
    "\n",
    "#Create a new dataframe that only contains the demographic information that's included in each survey\n",
    "\n",
    "common_columns = list(set(index1.columns).intersection(set(index7.columns)))\n",
    "\n",
    "common_data = pd.concat([index1[common_columns],\n",
    "                         index4[common_columns],\n",
    "                         index5[common_columns],\n",
    "                         index6[common_columns],\n",
    "                         index7[common_columns]\n",
    "                        ])\n",
    "\n",
    "#Drop the columns that don't contain demographic information\n",
    "\n",
    "common_data.drop(['ID', 'ADID IDFA', 'Time Started', 'Time Finished'], axis=1, inplace=True)\n",
    "\n",
    "#Get count of respondents by state\n",
    "\n",
    "common_data.groupby(['Area']).size().reset_index().values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.798127Z",
     "start_time": "2018-03-04T22:01:11.723054Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Encode whether or not a respodent will vote in the 2018 House of Representatives election\n",
    "\n",
    "def will_vote(answer):\n",
    "    if answer == \"Won't Vote\":\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "#Encode whether or not a respondent will vote for a major party candidate given that he/she will be voting\n",
    "    \n",
    "def will_vote_major(answer):\n",
    "    if answer == 'Will vote Republican' or answer == 'Will vote Democratic':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "#Encode which major party candidate a respondent will vote for given that he/she will be voting for a major party candidate\n",
    "    \n",
    "def which_major(answer):\n",
    "    if answer == 'Will vote Republican':\n",
    "        return 0\n",
    "    elif answer == 'Will vote Democratic':\n",
    "        return 1\n",
    "    \n",
    "def encode_demo(index):\n",
    "    #Create separate LabelEncoder instances for each variable so that they can be used to perform inverse transformations on the results later\n",
    "\n",
    "    gender_enc = LabelEncoder()\n",
    "    race_enc = LabelEncoder()\n",
    "    age_enc = LabelEncoder()\n",
    "    area_enc = LabelEncoder()\n",
    "    edu_enc = LabelEncoder()\n",
    "    div_enc = LabelEncoder()\n",
    "\n",
    "    race_gender_enc = LabelEncoder()\n",
    "    age_edu_enc = LabelEncoder()\n",
    "    age_gender_enc = LabelEncoder()\n",
    "    edu_gender_enc = LabelEncoder()\n",
    "\n",
    "    #Encode the gender, race, age, education, and state categories as integers\n",
    "\n",
    "    index['Gender Encoded'] = gender_enc.fit_transform(index['Gender'])\n",
    "    index['Race Encoded'] = race_enc.fit_transform(index['Race'])\n",
    "    index['Age Encoded'] = age_enc.fit_transform(index['Age'])\n",
    "    index['Area Encoded'] = area_enc.fit_transform(index['Area'])\n",
    "    index['Education Encoded'] = edu_enc.fit_transform(index['Education'])\n",
    "    index['Division Encoded'] = div_enc.fit_transform(index['US Census Division'])\n",
    "\n",
    "    #Create new columns for the marginal categories\n",
    "\n",
    "    index['Race_Gender'] = index['Race'].str.cat(index['Gender'], sep='|')\n",
    "    index['Age_Education'] = index['Age'].str.cat(index['Education'], sep='|')\n",
    "    index['Age_Gender'] = index['Age'].str.cat(index['Gender'], sep='|')\n",
    "    index['Education_Gender'] = index['Education'].str.cat(index['Gender'], sep='|')\n",
    "\n",
    "    #Encode the marginal categories as integers\n",
    "\n",
    "    index['Race_Gender'] = race_gender_enc.fit_transform(index['Race_Gender'])\n",
    "    index['Age_Education'] = age_edu_enc.fit_transform(index['Age_Education'])\n",
    "    index['Age_Gender'] = age_gender_enc.fit_transform(index['Age_Gender'])\n",
    "    index['Education_Gender'] = edu_gender_enc.fit_transform(index['Education_Gender'])\n",
    "\n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.861188Z",
     "start_time": "2018-03-04T22:01:11.799129Z"
    }
   },
   "outputs": [],
   "source": [
    "index1['Will Vote'] = index1['Who will you vote for in the House of Representatives in 2018?'].apply(lambda row: will_vote(row))\n",
    "index1['Will Vote Major'] = index1['Who will you vote for in the House of Representatives in 2018?'].apply(lambda row: will_vote_major(row))\n",
    "index1['Which Major'] = index1['Who will you vote for in the House of Representatives in 2018?'].apply(lambda row: which_major(row))\n",
    "\n",
    "common_data = encode_demo(common_data)\n",
    "index1 = encode_demo(index1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.875201Z",
     "start_time": "2018-03-04T22:01:11.862189Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#Group by race, gender, education, and age to see how many are in each cell and how many in each cell will vote\n",
    "\n",
    "index1_unique = index1.groupby(['Race Encoded',\n",
    "                                'Gender Encoded',\n",
    "                                'Education Encoded',\n",
    "                                'Age Encoded',\n",
    "                                'Area Encoded',\n",
    "                                'Division Encoded',\n",
    "                                'Race_Gender',\n",
    "                                'Age_Education',\n",
    "                                'Age_Gender',\n",
    "                                'Education_Gender'])['Will Vote']\n",
    "index1_unique = index1_unique.agg([('Will Vote', 'sum'), ('n', 'size')]).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.888214Z",
     "start_time": "2018-03-04T22:01:11.877204Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Obtain a mapping from each state to its census division\n",
    "\n",
    "division_map = common_data.groupby(['Area', 'US Census Division', 'Area Encoded', 'Division Encoded']).size().reset_index()[['Area', 'US Census Division', 'Area Encoded', 'Division Encoded']]\n",
    "\n",
    "#Remove duplicate state rows where the census division is missing\n",
    "\n",
    "division_map = division_map.loc[division_map['US Census Division'] != 'Unknown'].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.906231Z",
     "start_time": "2018-03-04T22:01:11.889215Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load the 2016 Presidential Election results by state\n",
    "\n",
    "state_df = pd.read_csv('demographics/US Presidential Results & PVIs by State 1828-2016 - 2-Party US Pres Results & PVIs.csv',\n",
    "                       header=1, usecols=[0, 2])\n",
    "state_df.columns = ['Area', 'Trump Vote']\n",
    "\n",
    "#Use the same name for Washington D.C. in both dataframes\n",
    "\n",
    "state_df.loc[state_df['Area'] == 'Washington DC', 'Area'] = 'District of Columbia'\n",
    "\n",
    "\n",
    "#Join the 2016 Election results with the census divisions\n",
    "\n",
    "state_df = state_df.merge(division_map)\n",
    "\n",
    "#Calculate the log odds of the proportion of each state's voters that voted for Donald Trump in 2016\n",
    "\n",
    "state_trump = logit(state_df['Trump Vote'].values/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.922247Z",
     "start_time": "2018-03-04T22:01:11.907233Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create Theano constant variables for the demographic and marginal demographic variables\n",
    "\n",
    "age = shared(index1_unique['Age Encoded'].values)\n",
    "edu = shared(index1_unique['Education Encoded'].values)\n",
    "race = shared(index1_unique['Race Encoded'].values)\n",
    "gender = shared(index1_unique['Gender Encoded'].values)\n",
    "area = shared(index1_unique['Area Encoded'].values)\n",
    "div = shared(index1_unique['Division Encoded'].values)\n",
    "\n",
    "age_gender = shared(index1_unique['Age_Gender'].values)\n",
    "race_gender = shared(index1_unique['Race_Gender'].values)\n",
    "age_edu = shared(index1_unique['Age_Education'].values)\n",
    "edu_gender = shared(index1_unique['Education_Gender'].values)\n",
    "\n",
    "#Create a Theano constant variable for the number of observations in each population cell\n",
    "\n",
    "n = shared(index1_unique['n'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:11.928253Z",
     "start_time": "2018-03-04T22:01:11.923248Z"
    }
   },
   "outputs": [],
   "source": [
    "#Define the model for the state-level effects coefficient\n",
    "\n",
    "def hierarchical_normal(name, shape, mu=0):\n",
    "    delta = pm.Normal('delta_{}'.format(name), 0, 1, shape=shape)\n",
    "    sigma = pm.HalfCauchy('sigma_{}'.format(name), 5)\n",
    "    \n",
    "    return pm. Deterministic(name, mu + delta*sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:12.071393Z",
     "start_time": "2018-03-04T22:01:11.929254Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This section creates the state-level variables.\n",
    "===============================================\n",
    "\n",
    "The length of the alpha_division coefficient vector is\n",
    "the number of unique census divisions.\n",
    "The length of the alpha_state coefficient vector is the\n",
    "number of unique state values, excluding \"Unknown\".\n",
    "\n",
    "The alpha_division and alpha_state variables have a mean of 0 and\n",
    "a standard deviation of delta*sigma, where delta is sampled from a\n",
    "normal distribution with a mean of 0 and standard deviation of 1, and\n",
    "sigma is sampled from a half Cauchy distribution with beta = 5.\n",
    "\n",
    "The beta_trump variable is the intercept for the support for Trump in\n",
    "each state in the 2016 election. This variable is normally distributed\n",
    "with a mean of 0 and a standard deviation of 5.b\n",
    "\n",
    "The mu_state vector represents the mean for each of the 50 states\n",
    "and Washington DC.\n",
    "The state_trump vector is the log odds of support for Trump in each state\n",
    "in the 2016 election.\n",
    "\"\"\"\n",
    "\n",
    "with pm.Model() as model:\n",
    "    alpha_division = hierarchical_normal('region',\n",
    "                                       common_data['Division Encoded'].unique().size)\n",
    "    beta_trump = pm.Normal('trump', 0. ,5)\n",
    "    mu_state = alpha_division[division_map['Division Encoded'].values] + beta_trump*state_trump\n",
    "    alpha_state = hierarchical_normal('state',\n",
    "                                      common_data['Area Encoded'].unique().size - 1,\n",
    "                                      mu=mu_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:12.755056Z",
     "start_time": "2018-03-04T22:01:12.072393Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This section creates the general population variables.\n",
    "======================================================\n",
    "\n",
    "The intercept beta_0 uses an initial value for sampling that's equal to\n",
    "the log odds of a respondent voting based on the survey responses.\n",
    "\n",
    "Each of the general population demographic and marginal demographic\n",
    "variables have a mean of 0 and a standard deviation of delta*sigma,\n",
    "where delta is sampled from a normal distribution with a mean of 0\n",
    "and standard deviation of 1, and sigma is sampled from a\n",
    "half Cauchy distribution with beta = 5.\n",
    "\n",
    "The variable eta is the multilevel logistic regression model that models\n",
    "the log odds of the voter turnout rate.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with model:\n",
    "    beta_0 = pm.Normal('beta_0', 0, 5,\n",
    "                       testval=logit(index1['Will Vote'].mean()))\n",
    "    \n",
    "    alpha_race_gender = hierarchical_normal('race_gender',\n",
    "                                            index1['Race_Gender'].unique().size)\n",
    "    alpha_age_gender = hierarchical_normal('age_gender',\n",
    "                                           index1['Age_Gender'].unique().size)\n",
    "    alpha_age_edu = hierarchical_normal('age_education',\n",
    "                                        index1['Age_Education'].unique().size)\n",
    "    alpha_edu_gender = hierarchical_normal('education_gender',\n",
    "                                           index1['Education_Gender'].unique().size)\n",
    "    \n",
    "    alpha_age = hierarchical_normal('age',\n",
    "                                    index1['Age'].unique().size)\n",
    "    alpha_edu = hierarchical_normal('education',\n",
    "                                    index1['Education'].unique().size)\n",
    "    alpha_race = hierarchical_normal('race',\n",
    "                                     index1['Race'].unique().size)\n",
    "    alpha_gender = hierarchical_normal('gender',\n",
    "                                       index1['Gender'].unique().size)\n",
    "    alpha_area = hierarchical_normal('area',\n",
    "                                     index1['Area'].unique().size)\n",
    "    alpha_div = hierarchical_normal('division',\n",
    "                                    index1['US Census Division'].unique().size)\n",
    "    \n",
    "    eta = (beta_0 +\n",
    "           alpha_race_gender[race_gender] + \n",
    "           alpha_age_gender[age_gender] +\n",
    "           alpha_age_edu[age_edu] + \n",
    "           alpha_edu_gender[edu_gender] + \n",
    "           alpha_age[age] +\n",
    "           alpha_edu[edu] +\n",
    "           alpha_race[race] + \n",
    "           alpha_gender[gender] + \n",
    "           alpha_area[area] + \n",
    "           alpha_div[div])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-04T22:01:12.831130Z",
     "start_time": "2018-03-04T22:01:12.756057Z"
    }
   },
   "outputs": [],
   "source": [
    "with model:\n",
    "    p = pm.math.sigmoid(eta)\n",
    "    obs = pm.Binomial('obs', n, p,\n",
    "                      observed=index1_unique['Will Vote'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-03-04T22:01:09.519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using advi...\n",
      "Average Loss = 471.66:  15%|███████▍                                          | 29898/200000 [48:59<4:38:42, 10.17it/s]\n",
      "Convergence archived at 29900\n",
      "Interrupted at 29,899 [14%]: Average Loss = 590.67\n",
      "C:\\Anaconda3\\envs\\MSR\\lib\\site-packages\\pymc3\\model.py:384: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not np.issubdtype(var.dtype, float):\n",
      "Multiprocess sampling (6 chains in 6 jobs)\n",
      "NUTS: [sigma_division_log__, delta_division, sigma_area_log__, delta_area, sigma_gender_log__, delta_gender, sigma_race_log__, delta_race, sigma_education_log__, delta_education, sigma_age_log__, delta_age, sigma_education_gender_log__, delta_education_gender, sigma_age_education_log__, delta_age_education, sigma_age_gender_log__, delta_age_gender, sigma_race_gender_log__, delta_race_gender, beta_0, sigma_state_log__, delta_state, trump, sigma_region_log__, delta_region]\n"
     ]
    }
   ],
   "source": [
    "with model:\n",
    "    trace = pm.sample(draws=1000,\n",
    "                      nuts_kwargs={'target_accept': 0.99},\n",
    "                      init='advi',\n",
    "                      njobs=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MSR]",
   "language": "python",
   "name": "conda-env-MSR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "notify_time": "30"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
